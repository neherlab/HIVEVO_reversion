# HIVEVO_reversion
Repository for the analysis and figures of the paper "Reversion to consensus are positively selected in HIV-1 and bias substitution rate estimates" by Valentin Druelle and Richard Neher.
This repository contains a compressed version of the intermediate data used to create the figures along with the scripts needed for that. 
It also contains the scripts to generate the intermediate data yourself if needed.
The raw files being too heavy for a github repository, you will have to download the full dataset yourself.

## Figure plots
All the figures are plotted using the `Paper_figures.py` script.
You will have to uncompress the intermediate data as explained in the following seciton.
## Working with the intermediate files
`data_mini/` contains the minimal data necessary to run the figures in compressed format. 
One can use the `unpack_data.sh` script to uncompress it. 
With this you should be able to redo the figures using the script `scripts/Paper_figures.py`

## Working with the raw files
This section is intended for people that which to regenerate the intermediate files. This is computationaly intensive and will take several hours on a regular laptop.

The full dataset folder can be found here: TODO. 
It contains both the raw data and the intermediate files needed for the analysis.
One can remove the intermediate files using `snakemake clean --cores 1` and regenerate them as explained in the following secitons.
### Generate between host data
For the between host analysis, make sure the raw data is in the `data/BH/raw` folder, then use snakemake to execute the rule `all`. 
This can be done with the command `snakemake all --cores 8` to run it on 8 cores for example.
This will compute a bunch of files for the 3 HIV-1 genes studied, which can take a lot of time. 
Details on how to do this in section "Sidenote: use on the cluster".

### Generate within host and modeling data
The WH intermediate data is generated by using the HIVevo_access repo: https://github.com/neherlab/HIVEVO_access
It also requires the files from the between host analysis, so one has to generate them first.
Generate the intermediate data by using `python scripts/WH_intermediate_data.py make-data`.
Note that to run properly, one needs to set the correct paths to the HIVevo access folder in the `scripts/filenames.py` file.
It will generate all the intermediate data needed for the within host analysis.
One can use `python scripts/WH_intermediate_data.py clean-data` to remove the intermediate data.

## Sidenote : use on the cluster
Generating the intermediate files (both for the BH and WH analysis) is computationnaly intensive. The whole thing will take several hours if run on a laptop.
The generation of the BH data can be speed up using a cluster to run the snakemake rules.
Command to launch the jobs on the cluster:
`snakemake all --jobs=16 --cluster "sbatch --time={cluster.time} --mem={cluster.mem} --cpus-per-task={cluster.n} --qos={cluster.qos}" --jobscript snake_submit.sh --cluster-config cluster.json --jobname "{rulename}_{jobid}" `
